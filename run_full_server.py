#!/usr/bin/env python3
"""
å®Œæ•´åŠŸèƒ½æœåŠ¡å™¨å¯åŠ¨è„šæœ¬ - åŒ…å«çœŸå®AIåŠŸèƒ½
"""

import os
import sys
import tempfile
import shutil
from pathlib import Path
from typing import List

# æ·»åŠ serverç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), 'server'))

from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
from yt_dlp import YoutubeDL

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv("server/.env")

# æ£€æŸ¥OpenAIé…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
WHISPER_MODEL = os.getenv("WHISPER_MODEL", "whisper-1")
SUMMARY_MODEL = os.getenv("SUMMARY_MODEL", "gpt-4o-mini")
TMP_DIR = Path(os.getenv("TMP_DIR", "./tmp"))
TMP_DIR.mkdir(parents=True, exist_ok=True)

print(f"ğŸ”‘ OpenAI API Key: {'âœ… å·²é…ç½®' if OPENAI_API_KEY and OPENAI_API_KEY != 'your_openai_api_key_here' else 'âŒ æœªé…ç½®'}")
print(f"ğŸ¤ Whisper Model: {WHISPER_MODEL}")  
print(f"ğŸ§  Summary Model: {SUMMARY_MODEL}")
print(f"ğŸ“ ä¸´æ—¶ç›®å½•: {TMP_DIR}")

# å°è¯•å¯¼å…¥å’Œåˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
try:
    from openai import OpenAI
    client = OpenAI(api_key=OPENAI_API_KEY)
    print("âœ… OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    client = None

# å¯¼å…¥æç¤ºè¯æ¨¡æ¿
try:
    from prompts import SYSTEM_SUMMARY, USER_TEMPLATE
    print("âœ… æç¤ºè¯æ¨¡æ¿åŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æç¤ºè¯æ¨¡æ¿åŠ è½½å¤±è´¥: {e}")
    # å†…åµŒæç¤ºè¯ä½œä¸ºåå¤‡
    SYSTEM_SUMMARY = "ä½ æ˜¯èµ„æ·±æŠ•ç ”åŠ©æ‰‹ã€‚è¯·åŸºäºè½¬å½•æ–‡æœ¬ï¼Œæç‚¼ã€3â€“5æ¡ã€‘'ç»“è®º/è¦ç‚¹'ã€‚"
    USER_TEMPLATE = "ç›®æ ‡è¯­è¨€: {lang}\n\nä»¥ä¸‹æ˜¯è½¬å½•æ–‡æœ¬ï¼š\n\n{transcript}\n\nè¯·è¾“å‡º3â€“5æ¡è¦ç‚¹ã€‚"

app = FastAPI(title="YouTube Video Summarizer - Full Version", description="Complete AI-powered video analysis")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class SummaryResp(BaseModel):
    video_id: str
    conclusions: List[str]
    summary: str
    transcript_preview: str

def download_audio_by_video_id(video_id: str, out_dir: Path) -> Path:
    """ä¸‹è½½YouTubeè§†é¢‘éŸ³é¢‘"""
    url = f"https://www.youtube.com/watch?v={video_id}"
    ydl_opts = {
        "format": "bestaudio/best",
        "outtmpl": str(out_dir / f"%(id)s.%(ext)s"),
        "noplaylist": True,
        "quiet": False,  # æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºä»¥ä¾¿è°ƒè¯•
        "no_warnings": False,
        "cachedir": False,
        # åæœºå™¨äººæ£€æµ‹è®¾ç½®
        "http_headers": {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        },
        "extractor_retries": 3,
        "fragment_retries": 10,
        "retry_sleep_functions": {"http": lambda n: min(4 * n, 60)},
        # ä½¿ç”¨cookiesï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        "cookiefile": None,
        "postprocessors": [{
            "key": "FFmpegExtractAudio",
            "preferredcodec": "mp3",
            "preferredquality": "192"
        }]
    }
    
    print(f"ğŸµ å¼€å§‹ä¸‹è½½éŸ³é¢‘: {url}")
    with YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=True)
        audio_path = out_dir / f"{info['id']}.mp3"
        if not audio_path.exists():
            # å…œåº•æŸ¥æ‰¾
            for f in out_dir.glob(f"{info['id']}.*"):
                if f.suffix.lower() in {'.m4a', '.mp3', '.webm'}:
                    print(f"âœ… éŸ³é¢‘ä¸‹è½½æˆåŠŸ: {f}")
                    return f
            raise FileNotFoundError("éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")
        print(f"âœ… éŸ³é¢‘ä¸‹è½½æˆåŠŸ: {audio_path}")
        return audio_path

def transcribe_whisper(file_path: Path) -> str:
    """ä½¿ç”¨Whisper APIè½¬å½•éŸ³é¢‘"""
    if not client:
        raise HTTPException(status_code=500, detail="OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
    
    print(f"ğŸ¤ å¼€å§‹è½¬å½•éŸ³é¢‘: {file_path}")
    with open(file_path, "rb") as f:
        transcription = client.audio.transcriptions.create(
            model=WHISPER_MODEL,
            file=f,
            temperature=0,
            response_format="json"
        )
    
    transcript = transcription.text
    print(f"âœ… è½¬å½•å®Œæˆï¼Œé•¿åº¦: {len(transcript)} å­—ç¬¦")
    return transcript

def summarize_conclusions(transcript: str, lang: str = "zh") -> tuple[List[str], str]:
    """ä½¿ç”¨GPTç”Ÿæˆç»“è®ºæ€»ç»“"""
    if not client:
        raise HTTPException(status_code=500, detail="OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
    
    print(f"ğŸ§  å¼€å§‹AIæ€»ç»“ï¼Œè¾“å…¥é•¿åº¦: {len(transcript)} å­—ç¬¦")
    
    sys_prompt = SYSTEM_SUMMARY
    user_prompt = USER_TEMPLATE.format(lang=lang, transcript=transcript[:18000])  # é˜²æ­¢è¶…é•¿

    resp = client.chat.completions.create(
        model=SUMMARY_MODEL,
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.2,
    )
    text = resp.choices[0].message.content.strip()
    print(f"âœ… AIæ€»ç»“å®Œæˆ")

    # ç®€å•è§£æï¼šæŒ‰è¡Œåˆ†å‰²ï¼Œæå–å‰3â€“6æ¡
    lines = [l.strip("- â€¢\t ") for l in text.splitlines() if l.strip()]
    conclusions = []
    overall = []
    for l in lines:
        if l.startswith("æ•´ä½“è§‚ç‚¹") or l.lower().startswith("overall"):
            overall.append(l)
        else:
            conclusions.append(l)
    return conclusions[:6], "\n".join(overall)

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - æœåŠ¡çŠ¶æ€æ£€æŸ¥"""
    return {
        "message": "YouTube Video Summarizer API - Full Version",
        "status": "running",
        "openai_configured": bool(client),
        "endpoints": {
            "summarize": "/api/summarize?video_id=VIDEO_ID&lang=zh",
            "docs": "/docs"
        }
    }

@app.get("/api/summarize", response_model=SummaryResp)
async def api_summarize(video_id: str = Query(...), lang: str = Query("zh")):
    """å®Œæ•´ç‰ˆæ€»ç»“API - çœŸå®AIå¤„ç†"""
    
    if not OPENAI_API_KEY or OPENAI_API_KEY == "your_openai_api_key_here":
        raise HTTPException(
            status_code=400, 
            detail="è¯·é…ç½®æœ‰æ•ˆçš„OpenAI APIå¯†é’¥"
        )
    
    if not client:
        raise HTTPException(
            status_code=500, 
            detail="OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
        )

    print(f"ğŸ“¹ å¼€å§‹å¤„ç†è§†é¢‘: {video_id}")
    work = Path(tempfile.mkdtemp(dir=TMP_DIR))
    
    try:
        # 1. ä¸‹è½½éŸ³é¢‘
        audio_file = download_audio_by_video_id(video_id, work)
        
        # 2. è½¬å½•éŸ³é¢‘
        transcript = transcribe_whisper(audio_file)
        
        # 3. AIæ€»ç»“
        conclusions, overall = summarize_conclusions(transcript, lang=lang)

        # 4. ç”Ÿæˆé¢„è§ˆ
        preview = transcript[:1200] + ("â€¦" if len(transcript) > 1200 else "")
        
        result = SummaryResp(
            video_id=video_id,
            conclusions=conclusions or ["æœªæå–åˆ°æ˜ç¡®ç»“è®ºï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æ€»ç»“æˆ–é‡è¯•ã€‚"],
            summary=overall,
            transcript_preview=preview,
        )
        
        print(f"ğŸ‰ å¤„ç†å®Œæˆ: {len(conclusions)} æ¡ç»“è®º")
        return result
        
    except Exception as e:
        print(f"âŒ å¤„ç†å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            shutil.rmtree(work, ignore_errors=True)
        except Exception:
            pass

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ å¯åŠ¨å®Œæ•´ç‰ˆ YouTube æ€»ç»“æœåŠ¡...")
    print("ğŸ“¡ æœåŠ¡å°†è¿è¡Œåœ¨: http://localhost:8000")
    print("ğŸ“– API æ–‡æ¡£: http://localhost:8000/docs")
    print("âš ï¸  è¯·ç¡®ä¿å·²é…ç½®æœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
    print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("-" * 60)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )