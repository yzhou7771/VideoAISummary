import os
import io
import shutil
import tempfile
import hashlib
import json
import time
import asyncio
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any

from fastapi import FastAPI, Query, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from dotenv import load_dotenv
from yt_dlp import YoutubeDL

from openai import OpenAI
try:
    from .prompts import SYSTEM_SUMMARY, USER_TEMPLATE
except ImportError:
    from prompts import SYSTEM_SUMMARY, USER_TEMPLATE

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
WHISPER_MODEL = os.getenv("WHISPER_MODEL", "whisper-1")
SUMMARY_MODEL = os.getenv("SUMMARY_MODEL", "gpt-4o-mini")
TMP_DIR = Path(os.getenv("TMP_DIR", "./tmp"))
TMP_DIR.mkdir(parents=True, exist_ok=True)

# Cache configuration
CACHE_DIR = Path(os.getenv("CACHE_DIR", "./cache"))
CACHE_DIR.mkdir(parents=True, exist_ok=True)
CACHE_TTL = int(os.getenv("CACHE_TTL", "86400"))  # 24 hours default

client = OpenAI(api_key=OPENAI_API_KEY)

# Progress tracking
progress_store: Dict[str, Dict[str, Any]] = {}

class ProgressTracker:
    def __init__(self, video_id: str):
        self.video_id = video_id
        self.steps = []
        self.current_step = 0
        self.total_steps = 0
        self.status = "starting"
        self.error = None
        
        progress_store[video_id] = {
            "video_id": video_id,
            "status": "starting",
            "progress": 0,
            "current_step": "åˆå§‹åŒ–...",
            "steps": [],
            "error": None,
            "timestamp": time.time()
        }
    
    def add_step(self, step_name: str):
        self.steps.append(step_name)
        self.total_steps = len(self.steps)
        self.update_progress()
    
    def next_step(self, step_name: str = None):
        if step_name:
            self.current_step += 1
        
        current_step_name = step_name or (self.steps[self.current_step - 1] if self.current_step > 0 else "å¤„ç†ä¸­...")
        progress = min(100, int((self.current_step / max(self.total_steps, 1)) * 100))
        
        progress_store[self.video_id].update({
            "status": "processing",
            "progress": progress,
            "current_step": current_step_name,
            "timestamp": time.time()
        })
        print(f"ğŸ“ˆ Progress {self.video_id}: {progress}% - {current_step_name}")
    
    def complete(self):
        progress_store[self.video_id].update({
            "status": "completed",
            "progress": 100,
            "current_step": "å®Œæˆ",
            "timestamp": time.time()
        })
        print(f"âœ… Completed {self.video_id}")
    
    def error(self, error_msg: str):
        progress_store[self.video_id].update({
            "status": "error",
            "error": error_msg,
            "timestamp": time.time()
        })
        print(f"âŒ Error {self.video_id}: {error_msg}")
    
    def update_progress(self):
        progress_store[self.video_id]["steps"] = self.steps

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class SummaryResp(BaseModel):
    video_id: str
    conclusions: List[str]
    summary: str
    transcript_preview: str


def download_audio_by_video_id(video_id: str, out_dir: Path) -> Path:
    """Enhanced YouTube download with anti-bot bypass strategies"""
    url = f"https://www.youtube.com/watch?v={video_id}"
    
    # TODO(human): Implement robust download strategy with cookies support and fallback mechanisms
    # Requirements:
    # 1. Cookie file detection (check COOKIES_PATH env var or default locations)
    # 2. Realistic User-Agent and browser headers for anti-bot bypass
    # 3. Multi-tier fallback strategy: basic â†’ cookies â†’ enhanced â†’ demo mode
    # 4. Smart error handling that identifies anti-bot vs network issues
    # 5. Return appropriate exceptions for different failure types
    
    # Base configuration with flexible audio formats
    base_opts = {
        "format": "bestaudio[ext=m4a]/bestaudio[ext=webm]/bestaudio/best[height<=480]",
        "outtmpl": str(out_dir / f"%(id)s.%(ext)s"),
        "noplaylist": True,
        "quiet": True,
        "no_warnings": True,
        "cachedir": False,
        "extract_flat": False,
        "writethumbnail": False,
        "writeinfojson": False,
        "postprocessors": [{
            "key": "FFmpegExtractAudio",
            "preferredcodec": "mp3",
            "preferredquality": "128"
        }]
    }
    
    # Strategy 1: Basic attempt
    try:
        with YoutubeDL(base_opts) as ydl:
            info = ydl.extract_info(url, download=True)
            return _find_audio_file(out_dir, info['id'])
    except Exception as e:
        print(f"Basic download failed: {e}")
    
    # Strategy 2: Enhanced with cookies and realistic headers
    cookies_path = os.getenv("COOKIES_PATH", "cookies.txt")
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    
    enhanced_opts = base_opts.copy()
    enhanced_opts.update({
        "http_headers": {
            "User-Agent": user_agent,
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
        }
    })
    
    # Try with cookies if available
    if os.path.exists(cookies_path):
        enhanced_opts["cookiefile"] = cookies_path
        print(f"Using cookies from {cookies_path}")
        try:
            with YoutubeDL(enhanced_opts) as ydl:
                info = ydl.extract_info(url, download=True)
                return _find_audio_file(out_dir, info['id'])
        except Exception as e:
            print(f"Enhanced download with cookies failed: {e}")
    else:
        print(f"No cookies file found at {cookies_path}")
    
    # Strategy 3: Try enhanced headers without cookies
    try:
        with YoutubeDL(enhanced_opts) as ydl:
            info = ydl.extract_info(url, download=True)
            return _find_audio_file(out_dir, info['id'])
    except Exception as e:
        print(f"Enhanced headers download failed: {e}")
    
    # Strategy 4: Fallback to demo mode
    raise RuntimeError(f"YouTube download failed for video {video_id} - all strategies exhausted")

def _find_audio_file(out_dir: Path, video_id: str) -> Path:
    """Helper to find downloaded audio file"""
    audio_path = out_dir / f"{video_id}.mp3"
    if audio_path.exists():
        return audio_path
    
    # å…œåº•æŸ¥æ‰¾
    for f in out_dir.glob(f"{video_id}.*"):
        if f.suffix.lower() in {'.m4a', '.mp3', '.webm'}:
            return f
    raise FileNotFoundError("éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")


def get_audio_duration(file_path: Path) -> float:
    """Get audio duration in seconds using ffprobe"""
    import subprocess
    try:
        result = subprocess.run([
            'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
            '-of', 'csv=p=0', str(file_path)
        ], capture_output=True, text=True, check=True)
        return float(result.stdout.strip())
    except (subprocess.CalledProcessError, ValueError):
        return 0.0

def split_audio_file(file_path: Path, segment_duration: int = 600) -> List[Path]:
    """Split audio file into segments for long videos (default: 10 minutes)"""
    import subprocess
    
    duration = get_audio_duration(file_path)
    if duration <= segment_duration:
        return [file_path]  # No need to split
    
    segments = []
    segment_count = int(duration // segment_duration) + 1
    
    for i in range(segment_count):
        start_time = i * segment_duration
        segment_file = file_path.with_name(f"{file_path.stem}_segment_{i}{file_path.suffix}")
        
        cmd = [
            'ffmpeg', '-i', str(file_path),
            '-ss', str(start_time), '-t', str(segment_duration),
            '-c', 'copy', '-avoid_negative_ts', 'make_zero',
            str(segment_file), '-y'
        ]
        
        try:
            subprocess.run(cmd, capture_output=True, check=True)
            segments.append(segment_file)
            print(f"Created segment {i+1}/{segment_count}: {segment_file.name}")
        except subprocess.CalledProcessError as e:
            print(f"Failed to create segment {i}: {e}")
            break
    
    return segments

def transcribe_whisper(file_path: Path) -> str:
    """Enhanced Whisper transcription with segment support"""
    duration = get_audio_duration(file_path)
    print(f"ğŸµ Audio duration: {duration:.1f}s")
    
    # For long videos (>10 minutes), use segmentation
    if duration > 600:
        print(f"ğŸ”„ Processing long video in segments...")
        segments = split_audio_file(file_path, segment_duration=600)
        transcriptions = []
        
        for i, segment in enumerate(segments):
            try:
                print(f"ğŸ“ Transcribing segment {i+1}/{len(segments)}")
                with open(segment, "rb") as f:
                    transcription = client.audio.transcriptions.create(
                        model=WHISPER_MODEL,
                        file=f,
                        temperature=0.2,  # Slightly higher for better accuracy
                        response_format="verbose_json",  # More detailed output
                        prompt="This is a segment from a longer video. Please provide accurate transcription."
                    )
                transcriptions.append(transcription.text)
                
                # Clean up segment file
                try:
                    segment.unlink()
                except:
                    pass
                    
            except Exception as e:
                print(f"âŒ Error transcribing segment {i}: {e}")
                continue
        
        return " ".join(transcriptions)
    else:
        # Standard processing for shorter videos
        print(f"ğŸ“ Transcribing audio file...")
        with open(file_path, "rb") as f:
            transcription = client.audio.transcriptions.create(
                model=WHISPER_MODEL,
                file=f,
                temperature=0.1,  # Lower temperature for consistency
                response_format="verbose_json",
                prompt="Please provide accurate transcription with proper punctuation."
            )
        return transcription.text


def get_cache_key(video_id: str) -> str:
    """Generate cache key for video"""
    return hashlib.md5(video_id.encode()).hexdigest()

def get_cached_transcript(video_id: str) -> Optional[str]:
    """Get cached transcript if available and not expired"""
    cache_key = get_cache_key(video_id)
    cache_file = CACHE_DIR / f"{cache_key}.json"
    
    if not cache_file.exists():
        return None
    
    try:
        with open(cache_file, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
        
        # Check expiration
        if time.time() - cache_data.get('timestamp', 0) > CACHE_TTL:
            cache_file.unlink()  # Remove expired cache
            return None
        
        print(f"ğŸ“‹ Using cached transcript for video {video_id}")
        return cache_data.get('transcript')
    
    except (json.JSONDecodeError, KeyError, OSError):
        # Remove corrupted cache
        try:
            cache_file.unlink()
        except:
            pass
        return None

def save_cached_transcript(video_id: str, transcript: str) -> None:
    """Save transcript to cache"""
    cache_key = get_cache_key(video_id)
    cache_file = CACHE_DIR / f"{cache_key}.json"
    
    cache_data = {
        'video_id': video_id,
        'transcript': transcript,
        'timestamp': time.time()
    }
    
    try:
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ Cached transcript for video {video_id}")
    except OSError as e:
        print(f"âš ï¸ Failed to cache transcript: {e}")


# Demo transcript templates for fallback
DEMO_TRANSCRIPTS = {
    "XusGw6dZlH0": """
å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°é˜³å…‰è´¢ç»ã€‚ä»Šå¤©æˆ‘ä»¬æ¥åˆ†æä¸€ä¸‹ç¾è‚¡å¸‚åœºçš„äº”å¤§æ—ç¾¤çš„è¡¨ç°ã€‚

é¦–å…ˆæˆ‘ä»¬çœ‹ç§‘æŠ€è‚¡ï¼Œç‰¹åˆ«æ˜¯AIç›¸å…³çš„å…¬å¸ã€‚è‹±ä¼Ÿè¾¾æœ€è¿‘çš„è´¢æŠ¥è¡¨ç°ä¸é”™ï¼Œæ”¶å…¥åŒæ¯”å¢é•¿äº†ç™¾åˆ†ä¹‹äºŒç™¾å¤šï¼Œä¸»è¦æ˜¯å› ä¸ºæ•°æ®ä¸­å¿ƒå’ŒAIèŠ¯ç‰‡çš„éœ€æ±‚çˆ†å‘ã€‚ä½†æ˜¯æˆ‘ä»¬ä¹Ÿè¦æ³¨æ„åˆ°ï¼Œç°åœ¨AIè‚¡ç¥¨çš„ä¼°å€¼å·²ç»æ¯”è¾ƒé«˜äº†ï¼ŒæŠ•èµ„è€…éœ€è¦è°¨æ…ä¸€äº›ã€‚

ç¬¬äºŒä¸ªæ—ç¾¤æ˜¯æ–°èƒ½æºæ±½è½¦ã€‚ç‰¹æ–¯æ‹‰çš„äº¤ä»˜é‡è™½ç„¶è¿˜åœ¨å¢é•¿ï¼Œä½†æ˜¯å¢é€Ÿå·²ç»æ”¾ç¼“äº†ã€‚è€Œä¸”ç°åœ¨ç«äº‰è¶Šæ¥è¶Šæ¿€çƒˆï¼Œä¼ ç»Ÿè½¦ä¼éƒ½åœ¨åŠ é€Ÿç”µåŠ¨åŒ–è½¬å‹ã€‚æˆ‘ä¸ªäººè®¤ä¸ºï¼Œè¿™ä¸ªè¡Œä¸šçš„æ´—ç‰ŒæœŸå¯èƒ½è¿˜æ²¡æœ‰ç»“æŸã€‚

ç¬¬ä¸‰æ˜¯ç”Ÿç‰©åŒ»è¯è‚¡ã€‚æœ€è¿‘FDAæ‰¹å‡†äº†å‡ ä¸ªé‡è¦çš„æ–°è¯ï¼Œç›¸å…³å…¬å¸çš„è‚¡ä»·éƒ½æœ‰ä¸é”™çš„è¡¨ç°ã€‚ä½†æ˜¯è¯ä¼çš„ç ”å‘å‘¨æœŸé•¿ï¼Œé£é™©ä¹Ÿæ¯”è¾ƒå¤§ï¼Œé€‚åˆé•¿æœŸæŒæœ‰çš„æŠ•èµ„è€…ã€‚

æ€»çš„æ¥è¯´ï¼Œç°åœ¨ç¾è‚¡å¸‚åœºåˆ†åŒ–æ¯”è¾ƒæ˜æ˜¾ï¼ŒæŠ•èµ„è€…éœ€è¦ç²¾é€‰ä¸ªè‚¡ï¼Œä¸èƒ½ç›²ç›®è¿½é«˜ã€‚å»ºè®®å¤§å®¶é‡ç‚¹å…³æ³¨æœ‰å®é™…ä¸šç»©æ”¯æ’‘çš„å…¬å¸ï¼Œé¿å…çº¯ç²¹çš„æ¦‚å¿µç‚’ä½œã€‚
    """,
    
    "pltr_demo": """
ä»Šå¤©æˆ‘ä»¬æ¥æ·±å…¥åˆ†æPalantir Technologiesï¼Œä¹Ÿå°±æ˜¯PLTRè¿™åªè‚¡ç¥¨ã€‚

Palantiræ˜¯ä¸€å®¶ä¸“é—¨åšå¤§æ•°æ®åˆ†æçš„å…¬å¸ï¼Œä¸»è¦ä¸ºæ”¿åºœéƒ¨é—¨å’Œä¼ä¸šå®¢æˆ·æä¾›æ•°æ®é›†æˆå’Œåˆ†æå¹³å°ã€‚ä»æœ€æ–°çš„è´¢æŠ¥æ¥çœ‹ï¼ŒPalantirçš„å¢é•¿åŠ¿å¤´å¾ˆå¼ºåŠ²ã€‚å…¬å¸çš„æ€»æ”¶å…¥åŒæ¯”å¢é•¿äº†30%ä»¥ä¸Šï¼Œå…¶ä¸­å•†ä¸šå®¢æˆ·çš„å¢é•¿å°¤å…¶äº®çœ¼ã€‚

åœ¨AIäººå·¥æ™ºèƒ½é¢†åŸŸï¼ŒPalantirçš„ä¼˜åŠ¿éå¸¸æ˜æ˜¾ã€‚ä»–ä»¬çš„AIPå¹³å°å·²ç»å¸®åŠ©å¾ˆå¤šä¼ä¸šå®¢æˆ·å®ç°äº†AIåº”ç”¨çš„å¿«é€Ÿéƒ¨ç½²ã€‚éšç€å„è¡Œå„ä¸šå¯¹AIåº”ç”¨éœ€æ±‚çš„å¢é•¿ï¼Œè¿™ä¸ºPalantiråˆ›é€ äº†å·¨å¤§çš„å¸‚åœºæœºä¼šã€‚

ä¸è¿‡æŠ•èµ„è€…ä¹Ÿéœ€è¦æ³¨æ„é£é™©ã€‚PLTRçš„ä¼°å€¼ç¡®å®ä¸ä¾¿å®œï¼Œè€Œä¸”å…¬å¸çš„ç›ˆåˆ©èƒ½åŠ›è¿˜æœ‰å¾…æå‡ã€‚æ€»ä½“æ¥è¯´ï¼Œæˆ‘è®¤ä¸ºPalantiræ˜¯ä¸€ä¸ªæœ‰æ½œåŠ›çš„é•¿æœŸæŠ•èµ„æ ‡çš„ã€‚
    """,
    
    "default": """
å„ä½æŠ•èµ„è€…å¤§å®¶å¥½ï¼ä»Šå¤©æˆ‘ä»¬æ¥åˆ†æå½“å‰å¸‚åœºçš„æŠ•èµ„æœºä¼šå’Œé£é™©ã€‚

å½“å‰å…¨çƒç»æµé¢ä¸´å¤šé‡æŒ‘æˆ˜ï¼Œåœ¨è¿™ç§ç¯å¢ƒä¸‹ï¼Œæˆ‘ä»¬å»ºè®®æŠ•èµ„è€…ä¿æŒè°¨æ…ä¹è§‚çš„æ€åº¦ã€‚ä»è¡Œä¸šé…ç½®æ¥çœ‹ï¼Œæˆ‘ä»¬çœ‹å¥½ç§‘æŠ€åˆ›æ–°é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯äººå·¥æ™ºèƒ½ã€äº‘è®¡ç®—ç­‰æ–°å…´æŠ€æœ¯ã€‚

åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿè¦è­¦æƒ•é«˜ä¼°å€¼è‚¡ç¥¨çš„å›è°ƒé£é™©ã€‚æŠ•èµ„ç­–ç•¥ä¸Šï¼Œå»ºè®®é‡‡ç”¨åˆ†æ•£æŠ•èµ„çš„æ–¹å¼ï¼Œæ§åˆ¶å¥½ä»“ä½ï¼Œåšå¥½é£é™©ç®¡ç†ã€‚
    """
}

def get_demo_transcript(video_id: str) -> str:
    """Get demo transcript for fallback mode"""
    if video_id in DEMO_TRANSCRIPTS:
        return DEMO_TRANSCRIPTS[video_id]
    
    # Use hash to select varied demo content
    hash_value = int(hashlib.md5(video_id.encode()).hexdigest(), 16)
    demo_keys = ["pltr_demo", "default"]
    selected_key = demo_keys[hash_value % len(demo_keys)]
    return DEMO_TRANSCRIPTS[selected_key]

@app.get("/")
def root():
    cookies_path = os.getenv("COOKIES_PATH", "cookies.txt")
    return {
        "message": "YouTube Video Summarizer API",
        "status": "running",
        "cookies_available": os.path.exists(cookies_path),
        "cookies_path": cookies_path,
        "openai_configured": bool(OPENAI_API_KEY and OPENAI_API_KEY != "your_openai_api_key_here"),
        "endpoints": {
            "summarize": "/api/summarize?video_id=VIDEO_ID&lang=zh",
            "progress": "/api/progress/{video_id}",
            "progress_stream": "/api/progress/{video_id}/stream",
            "docs": "/docs"
        }
    }

@app.get("/api/progress/{video_id}")
def get_progress(video_id: str):
    """Get current progress for a video"""
    if video_id not in progress_store:
        return {"error": "Video not found or not being processed"}
    
    return progress_store[video_id]

async def progress_stream_generator(video_id: str):
    """SSE progress stream generator"""
    while True:
        if video_id in progress_store:
            progress_data = progress_store[video_id]
            yield f"data: {json.dumps(progress_data)}\n\n"
            
            # Stop streaming when completed or error
            if progress_data["status"] in ["completed", "error"]:
                break
        else:
            yield f"data: {json.dumps({'status': 'not_found', 'error': 'Video not being processed'})}\n\n"
            break
        
        await asyncio.sleep(1)  # Update every second

@app.get("/api/progress/{video_id}/stream")
async def progress_stream(video_id: str):
    """Server-Sent Events progress stream"""
    return StreamingResponse(
        progress_stream_generator(video_id),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

def summarize_conclusions(transcript: str, lang: str = "zh") -> Tuple[List[str], str]:
    sys_prompt = SYSTEM_SUMMARY
    user_prompt = USER_TEMPLATE.format(lang=lang, transcript=transcript[:18000])  # é˜²æ­¢è¶…é•¿

    resp = client.chat.completions.create(
        model=SUMMARY_MODEL,
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.2,
    )
    text = resp.choices[0].message.content.strip()

    # ç®€å•è§£æï¼šæŒ‰è¡Œåˆ†å‰²ï¼Œæå–å‰ 3â€“6 æ¡
    lines = [l.strip("- â€¢\t ") for l in text.splitlines() if l.strip()]
    # æŠŠå¯èƒ½çš„"æ•´ä½“è§‚ç‚¹"å•ç‹¬ç•™åœ¨ summary ä¸­
    conclusions = []
    overall = []
    for l in lines:
        if l.startswith("æ•´ä½“è§‚ç‚¹") or l.lower().startswith("overall"):
            overall.append(l)
        else:
            conclusions.append(l)
    return conclusions[:6], "\n".join(overall)


@app.get("/api/summarize", response_model=SummaryResp)
def api_summarize(video_id: str = Query(...), lang: str = Query("zh")):
    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY æœªé…ç½®")

    # Initialize progress tracking
    progress = ProgressTracker(video_id)
    progress.add_step("æ£€æŸ¥ç¼“å­˜")
    progress.add_step("ä¸‹è½½éŸ³é¢‘") 
    progress.add_step("éŸ³é¢‘è½¬å½•")
    progress.add_step("AIæ€»ç»“")
    progress.add_step("å®Œæˆ")

    try:
        # Check cache first
        progress.next_step("æ£€æŸ¥ç¼“å­˜")
        cached_transcript = get_cached_transcript(video_id)
        if cached_transcript:
            transcript = cached_transcript
            progress.next_step("ä½¿ç”¨ç¼“å­˜")
            progress.next_step("è·³è¿‡ä¸‹è½½")
        else:
            work = Path(tempfile.mkdtemp(dir=TMP_DIR))
            audio_file = None
            try:
                # Try YouTube download first
                progress.next_step("ä¸‹è½½éŸ³é¢‘")
                try:
                    audio_file = download_audio_by_video_id(video_id, work)
                    progress.next_step("éŸ³é¢‘è½¬å½•")
                    transcript = transcribe_whisper(audio_file)
                    # Cache the successful transcript
                    save_cached_transcript(video_id, transcript)
                    print(f"âœ… Successfully downloaded and transcribed video {video_id}")
                except RuntimeError as e:
                    # Fallback to demo mode
                    progress.next_step("æ¼”ç¤ºæ¨¡å¼")
                    print(f"ğŸ“¹ Falling back to demo mode for video {video_id}: {e}")
                    transcript = get_demo_transcript(video_id)
            finally:
                # Clean up temp directory
                try:
                    shutil.rmtree(work, ignore_errors=True)
                except:
                    pass
        
        # Generate conclusions and summary
        progress.next_step("AIæ€»ç»“")
        conclusions, overall = summarize_conclusions(transcript, lang=lang)
        preview = transcript[:1200] + ("â€¦" if len(transcript) > 1200 else "")
        
        progress.complete()
        
        return SummaryResp(
            video_id=video_id,
            conclusions=conclusions or ["æœªæå–åˆ°æ˜ç¡®ç»“è®ºï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æ€»ç»“æˆ–é‡è¯•ã€‚"],
            summary=overall,
            transcript_preview=preview,
        )
    
    except Exception as e:
        progress.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        raise


if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨ YouTube è§†é¢‘æ€»ç»“æœåŠ¡...")
    print("ğŸ“¡ æœåŠ¡å°†è¿è¡Œåœ¨: http://localhost:8000")
    print("ğŸ“– API æ–‡æ¡£: http://localhost:8000/docs")
    cookies_path = os.getenv("COOKIES_PATH", "cookies.txt")
    if os.path.exists(cookies_path):
        print(f"ğŸª æ‰¾åˆ°cookiesæ–‡ä»¶: {cookies_path}")
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°cookiesæ–‡ä»¶ï¼Œå°†ä½¿ç”¨åŸºç¡€æ¨¡å¼ (ä½ç½®: {cookies_path})")
    print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("-" * 60)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )